
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>★-Gen</title>

    <meta name="description" content="A Taxonomy for Evaluating Generalist Robot Policies">
    <meta name="viewport" content="width=device-width, initial-scale=1">
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://generalization-taxonomy.github.io/img/STAR-GEN/axes_v3.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://generalization-taxonomy.github.io/"/>
    <meta property="og:title" content="A Taxonomy for Evaluating Generalist Robot Policies" />
    <meta property="og:description" content="Project page for A Taxonomy for Evaluating Generalist Robot Policies." />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="A Taxonomy for Evaluating Generalist Robot Policies" />
    <meta name="twitter:description" content="Project page for A Taxonomy for Evaluating Generalist Robot Policies." />
    <!-- <meta name="twitter:image" content="https://rt-h.github.io/img/random_img_frames.png" /> -->


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>

    <script src="js/app.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-52J0PM8XKV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-52J0PM8XKV');
</script>

    <style>
        .nav-pills {
          position: relative;
          display: inline;
        }
        .imtip {
          position: absolute;
          top: 0;
          left: 0;
        }
        h1 {
            font-weight: bold;
        }
        h2 {
            font-weight: bold;
            text-align: center;
        }
        h4 {
            font-size: 23px;
        }
    </style>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <strong><font size="+6">A Taxonomy for Evaluating Generalist Robot Policies</font></strong> </br>
                <!--<small>
                    CoRL 2023
                </small>-->
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center authors">
                <ul class="list-inline">
                <br>
                <li>
                    <a href="https://scholar.google.com/citations?user=SnTMyGUAAAAJ&hl=en">Jensen Gao*</a><sup>1</sup>,
                    <a href="https://suneel.belkhale.com/">Suneel Belkhale*</a><sup>1</sup>,
                    <a href="https://sudeepdasari.github.io/">Sudeep Dasari</a><sup>2</sup>,
                    <a href="https://abalakrishna123.github.io/">Ashwin Balakrishna</a><sup>2</sup>,
                    <a href="https://robodhruv.github.io/">Dhruv Shah</a><sup>2</sup>,
                    <a href="https://dorsa.fyi/">Dorsa Sadigh</a><sup>1</sup>
                </li>
                <br>
                </ul>
                <sup>1</sup>Stanford University, <sup>2</sup>Google DeepMind Robotics
            </div>
            <br>
        </div>

        <div class="row">
            <div class="col-md-12">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://arxiv.org/" target="_blank">  <!-- TODO -->
                        <image src="img/paper.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <!-- <li>
                        <a href="https://console.cloud.google.com/storage/browser/gdm-robovqa" target="_blank">
                        <image src="img/storage_icon.png" height="60px">
                            <h4><strong>Data</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/google-deepmind/robovqa/tree/main" target="_blank">
                        <image src="img/github_icon.png" height="60px">
                            <h4><strong>Code</strong></h4>
                        </a>
                    </li> -->
                    <!-- <li>
                        <a href="#videos">
                        <image src="img/youtube_icon.png" height="60px">
                            <h4><strong>Videos</strong></h4>
                        </a>
                    </li> -->
                </ul>
            </div>
        </div>

        <div style="width: 90%; float: center; text-align:center; margin: 0 auto">
            <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/axes_v3.png" target="_blank">
                <figure>
                    <img src="img/STAR-GEN/axes_v3.png" class="img-responsive">
                </figure>
            </a>
            <!-- <br> -->
            <figcaption>★-Gen</figcaption>
        </div>
        <br>

        <div class="row" style="width: 80%; margin: 0 auto;">
            <div class="col-md-12">
                <h2>Abstract</h2>
                <p>
                    Machine learning for robotics promises to unlock generalization to novel tasks and environments.
                    Guided by this promise, many recent works have focused on scaling up robot data collection and developing larger, more expressive policies to achieve this.
                    But how do we measure progress towards this goal of policy generalization in practice?
                    Evaluating and quantifying generalization is the Wild West of modern robotics, with each work proposing and measuring different types of generalization in their own, often difficult to reproduce, settings.
                    In this work, our goal is (1) to outline the forms of generalization we believe are important in robot manipulation in a comprehensive and fine-grained manner, and (2) to provide reproducible guidelines for measuring these notions of generalization.
                    We first propose ★-Gen, a taxonomy of generalization for robot manipulation structured around semantic, visual, and behavioral generalization.
                    We discuss how our taxonomy encompasses most prior notions of generalization in robotics.
                    Next, we instantiate ★-Gen with a concrete real-world benchmark based on the widely-used Bridge V2 dataset.
                    We evaluate a variety of state-of-the-art models on this benchmark to demonstrate the utility of our taxonomy in practice.
                    Our taxonomy of generalization can yield many interesting insights into existing models: for example, we observe that current vision-language-action models struggle with various types of semantic generalization, despite the promise of pre-training on internet-scale language datasets.
                    We believe ★-Gen and our guidelines can improve the dissemination and evaluation of progress towards generalization in robotics, which we hope will guide model design and future data collection efforts.
                </p>
            </div>
        </div>



        <br>
        <hr class="section-divider">

        <!-- <h2>Video</h2>

        <p style="text-align:center; width: 80%; margin: 0 auto">
            <video id="bg-video" autoplay loop muted playsinline controls style="display: block; width: 100%;">
                <source src="videos/RT-H/rt_h_video_website.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </p> -->
        <div class="row">
            <div class="col-md-12">

                <h2>Our Taxonomy: ★-Gen</h2>
                <br>

                <p>
                    Generalization can be a nebulous, ill-defined concept. We formalize generalization intuitively as <b>perturbations</b> relative to some base task.
                    For vision-language-action models (VLAs), these perturbations can fall under three main types:
                    <li><b>Visual</b>: Changes to the initial image.</li>
                    <li><b>Semantic</b>: Changes to the task.</li>
                    <li><b>Behavioral</b>: Changes to the expert action distribution.</li>
                </p>
                <p>
                    A given perturbation might lie at the intersection of one or more of these types. For example, changing the location of a carrot in a "Put the carrot on the plate" task changes both the image (Visual) and the required actions (Behavioral).
                </p>

                <p>
                    Therefore we can categorize perturbations into <b>categories</b> of generalization depending on which combination of the above perturbation types they affect.
                    For example, changing the location of the carrot would fall under the Visual + Behavioral category.
                    We further group different perturbations in each category into human-interpretable <b>axes</b> of generalization. Below you can find the axes we have enumerated for each category of generalization.
                </p>

                <div style="width: 90%; float: center; text-align:center; margin: 0 auto">
                    <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/detailed_axes.png" target="_blank">
                        <figure>
                            <img src="img/STAR-GEN/detailed_axes.png" class="img-responsive">
                        </figure>
                    </a>
                    <figcaption>Detailed Axes of Generalization.</figcaption>
                </div>

                <br>
                <p>
                    These axes span a wide range of possible perturbations, and we show below that ★-Gen encompasses all notions of generalization in prior work:
                </p>

                <div style="width: 90%; float: center; text-align:center; margin: 0 auto">
                    <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/comparison_table.png" target="_blank">
                        <figure>
                            <img src="img/STAR-GEN/comparison_table.png" class="img-responsive">
                        </figure>
                    </a>
                    <figcaption>Comparing ★-Gen to notions of generalization in prior work, as well as our benchmark BridgeV2-★ .</figcaption>
                </div>

            </div>
        </div>

        <br>
        <hr class="section-divider">

        <h2>Instantiating our Taxonomy: BridgeV2-★</h2>
        <br>

        <div class="row">
            <div class="col-md-12">

                <p>
                    We walk through an example of instantiating our taxonomy ★-Gen into a real-world benchmark for generalization evaluation.
                    We use the popular Bridge-V2 dataset as a starting point, and we train several state of the art models on our starting data:
                    OpenVLA, MiniVLA, and \( \pi_0 \). We pick the following base tasks which are aligned with the Bridge-V2 dataset,
                    and we collect 20-50 additional demos to ensure they are in distribution for our setup.
                </p>

                <div style="width: 100%; float: center; text-align:center; margin: 0 auto">
                    <div style="width: 25%; float: left; text-align:center; margin: 0 auto">
                        <div style="width: 90%; float: center; text-align:center; margin: 0 auto">
                            <p><i>Put carrot on plate</i></p>
                        <figure>
                            <img src="img/STAR-GEN/scenes/carrot-knife/base.jpg" class="img-responsive">
                        </figure>
                        </div>
                    </div>
                    <div style="width: 25%; float: left; text-align:center; margin: 0 auto">
                        <div style="width: 90%; float: center; text-align:center; margin: 0 auto">
                            <p><i>Put knife on plate</i></p>
                        <figure>
                            <img src="img/STAR-GEN/scenes/carrot-knife/base.jpg" class="img-responsive">
                        </figure>
                        </div>
                    </div>
                    <div style="width: 25%; float: left; text-align:center; margin: 0 auto">
                        <div style="width: 90%; float: center; text-align:center; margin: 0 auto">
                            <p><i>Put plate in sink</i></p>
                        <figure>
                            <img src="img/STAR-GEN/scenes/pot-plate/base.jpg" class="img-responsive">
                        </figure>
                        </div>
                    </div>
                    <div style="width: 25%; float: left; text-align:center; margin: 0 auto">
                        <div style="width: 90%; float: center; text-align:center; margin: 0 auto">
                            <p><i>Flip pot upright in sink</i></p>
                        <figure>
                            <img src="img/STAR-GEN/scenes/pot-plate/base.jpg" class="img-responsive">
                        </figure>
                        </div>
                    </div>
                </div>

            </div>
        </div>

        <br>


        <div class="row">
            <div class="col-md-12">
                <p>
                    For each of these base tasks, we chose perturbations along a subset of our axes, since some axes did not have meaningful instatiations on this dataset.
                    Please refer to our paper for details on the specific evaluation tasks we used.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-12">

                <div style="width: 40%; float: left; text-align:center; margin: 0 auto; display: inline-block">
                    <div style="width: 95%; float: left; text-align:center; margin: 0 auto">
                        <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/results/main.png" target="_blank">
                            <figure>
                                <img src="img/STAR-GEN/results/main.png" class="img-responsive">
                            </figure>
                        </a>
                        <figcaption>BridgeV2-★ Main results.</figcaption>
                    </div>
                </div>
                <div style="width: 55%; float: center; text-align:left; margin: 0 auto; display: inline-block">
                <p>
                    Our main results on our BridgeV2-★ benchmark are shown on the left, which consists of in-distribution base task
                    performance, and 55 task variations that span 13 of our axes,
                    for a total of <b>885 real-world evaluations</b>. We find that existing
                    generalist policies tend to struggle on most of our considered
                    axes. In particular, semantic generalization is weak across
                    all models, despite them leveraging large language model
                    backbones trained on internet-scale data. This has interesting
                    implications: e.g., rather than relying soley on improvements
                    in language modeling to improve semantic generalization,
                    perhaps other mechanisms are needed, such as improving
                    language annotations in robot datasets.
                </p>
                <p>
                    Each model tends to have similar strengths and weaknesses
                    across our different axes. However, there are some notable
                    differences between each model that the fine-grained nature
                    of our benchmark helps reveal. For example, OpenVLA is
                    noticeably worse at visual generalization than the other models,
                    while MiniVLA struggles more with forms of visual
                    + behavioral generalization. OpenVLA performs the best
                    at understanding object properties which could be due to
                    it having the largest language model backbone, but it still
                    struggles with other forms of semantic generalization. \( \pi_0 \)
                    generally performs the best across all axes, possibly due to
                    a more capable VLM backbone (PaliGemma), and/or better
                    architecture design (flow-based action chunking). However,
                    like the other models, \( \pi_0 \) still generally struggles in terms
                    of absolute performance for most axes.
                </p>
                </div>
            </div>

        </div>

        <br>

        <div class="row">
            <div class="col-md-12">

                <div style="width: 50%; float: left; text-align:center; margin: 0 auto; display: inline-block">
                    <div style="width: 95%; float: left; text-align:center; margin: 0 auto">
                        <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/results/bridge_vs_oxe.png" target="_blank">
                            <figure>
                                <img src="img/STAR-GEN/results/bridge_vs_oxe.png" class="img-responsive">
                            </figure>
                        </a>
                        <figcaption style="text-align: left;">(a) <b>Scaling robot data</b>: it is
                            important to note that OXE is a significantly larger dataset that
                            contains Bridge V2, along with data from over 20 other robot
                            embodiments. Consistent with prior work, we find that
                            larger and more diverse robot datasets can significantly improve
                            overall generalization. However, we observe that while
                            generalization improves along several axes (especially some
                            semantic and visual axes), those that the Bridge-only model
                            struggled with the most (e.g., Viewpoint, Morphed Objects,
                            Multi-Object Referencing) do not improve significantly.</figcaption>
                    </div>
                </div>

                <div style="width: 50%; float: left; text-align:center; margin: 0 auto; display: inline-block">
                    <div style="width: 95%; float: left; text-align:left; margin: 0 auto">
                        <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/results/llm_scaling.png" target="_blank">
                            <figure>
                                <img src="img/STAR-GEN/results/llm_scaling.png" class="img-responsive">
                            </figure>
                        </a>
                        <figcaption style="text-align: left;">(b) <b>Scaling LLM backbone</b>: we compare VLA
                            policies that share the same architecture and differ only in
                            the large language model (LLM) backbone. Specifically, we
                            compare OpenVLA (Bridge, FT), using Llama 2 7B,
                            and MiniVLA (Bridge, –VQ, FT), using Qwen2.5 0.5B,
                            both using the same pre-trained vision encoder. Note that this
                            version of MiniVLA does not use vector quantized action
                            chunking (designated as –VQ), and the only major difference
                            between these two models is their LLM backbone. We find that
                            the larger LLM backbone does improve semantic generalization,
                            which makes intuitive sense. However, there still remain
                            large deficiencies in terms of absolute performance for these
                            axes, and there is much less effect on the others, suggesting
                            that scaling LLM size only has limited benefits.</figcaption>
                    </div>
                </div>


                <div style="width: 50%; float: left; text-align:center; margin: 0 auto; display: inline-block">
                    <div style="width: 95%; float: left; text-align:center; margin: 0 auto">
                        <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/results/vqa_coft.png" target="_blank">
                            <figure>
                                <img src="img/STAR-GEN/results/vqa_coft.png" class="img-responsive">
                            </figure>
                        </a>
                        <figcaption style="text-align: left;">(c) <b>VQA co-training</b>: we investigate the impact
                            of co-training with general visual-question answering (VQA)
                            data, which has been suggested in prior work to improve
                            VLA generalization. We find that VQA co-training does
                            generally improve generalization, but surprisingly has a mixed
                            effect for semantic axes, improving for 3 of them (Language
                            Rephrase, Multi-Object Referencing, Internet Knowledge), but
                            hurting another (Object Properties). This could indicate that
                            there is room for improvement when co-training VLAs, such
                            as by using VQA data that is targeted for inducing various
                            forms of policy generalization, rather than general VQA data.</figcaption>
                    </div>
                </div>

                <div style="width: 50%; float: left; text-align:center; margin: 0 auto; display: inline-block">
                    <div style="width: 95%; float: left; text-align:center; margin: 0 auto">
                        <a href="https://generalization-taxonomy.github.io/img/STAR-GEN/results/vq_vs_binning.png" target="_blank">
                            <figure>
                                <img src="img/STAR-GEN/results/vq_vs_binning.png" class="img-responsive">
                            </figure>
                        </a>
                        <figcaption style="text-align: left;">(d) <b>Vector Quantized Actions</b>:
                            we investigate the effect of removing vector quantized action chunking
                            (–VQ) from MiniVLA, and instead using the binning-
                            based tokenization from OpenVLA. We find that for nearly all
                            axes (except Interacting Scene), this change hurts generaliza-
                            tion. This is perhaps because action chunking helps the policy
                            resolve action uncertainty and multi-modality by committing
                            to certain action sequences, as hypothesized in prior work</figcaption>
                    </div>
                </div>
            </div>
        </div>

        <br>
        <hr class="section-divider">

        <h2>Example Generalization Axes & Evals </h2>
        <br>
        <p>Below we visualize rollouts from the policy under each of our axes of generalization tested in our benchmark BridgeV2-★.
            For each row, the left video shows the base task, and the right slider (and color-coded scroll buttons below the videos) shows an example generalization condition for that axis.
            These videos are real rollouts from MiniVLA.
        </p>

        <!-- CARROT -->
        <div class="full-slider-container">

            <!-- BASE -->
            <div class="video-container base-task" style="text-align: center; display:inline; float:left; width: 48%;">
                <video width="85%" controls loop autoplay muted>
                    <source src="videos/carrot/carrot_base.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p><b>BASE TASK</b>: Put carrot on plate</p>
            </div>

            <div class="slideshow-container" style="width: 48%; display: inline-block; float: right;">


                <!-- DISTRACTORS -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/carrot_distractors.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-SC</b>: <i>distractors</i></p>
                </div>

                <!-- VISUAL SCENE -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/carrot_orange_plate.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-OBJ</b>: <i>orange plate</i></p>
                </div>

                <!--VISUAL VIEW -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/carrot_camera.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-VIEW</b>: <i>new camera view</i></p>
                </div>

                <!-- SEMANTIC OBJECT PROP -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/carrot/carrot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-PROP</b>: Put the orange object on the plate</p>
                </div>

                <!-- SEMANTIC LANG REPHRASE -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/carrot/carrot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-LANG</b>: Lift carrot and place on plate</p>
                </div>

                <!-- SEMANTIC MULTI OBJ REFERING -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/carrot/carrot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-MO</b>: Put the object that is on the counter on the plate</p>
                </div>

                <!-- SEMANTIC INTERNET -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/carrot/carrot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-INT</b>: Put the object that is the same color as a basketball on the plate</p>
                </div>

                <!-- VISUAL+BEHAVIORAL POSE -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/carrot_farther.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-POSE</b>: <i>carrot farther away</i></p>
                </div>

                <!-- VISUAL+BEHAVIORAL SCENE ELEMENTS -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/carrot_shorter_table.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-ISC</b>: <i>shorter table height</i></p>
                </div>


                <!-- VISUAL+BEHAVIORAL OBJECT MORPH -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/baby_carrot.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-MOBJ</b>: <i>baby carrot</i></p>
                </div>

                <!-- SEMANTIC+BEHAVIORAL SPATIAL MULTI OBJECT -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/put_carrot_in_sink.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>SB-SMO</b>: Put carrot in sink</p>
                </div>

                <!-- VISUAL+SEMANTIC+BEHAVIORAL NEW OBJECT -->
                <div class="video-container slide-index-0" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/carrot/ball.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VSB-NOBJ</b>: Put ball on plate</p>
                </div>

                <div>
                    <!-- Next and previous buttons -->
                    <a class="prev" onclick="plusSlides(-1, idx=0)">&#10094;</a>
                    <a class="next" onclick="plusSlides(1, idx=0)">&#10095;</a>
                </div>
            </div>

        </div>

        <br>

        <div style="text-align: center; display: block;">
            <span class="vis dot slide-index-0" onclick="currentSlide(1, idx=0)">SC</span>
            <span class="vis dot slide-index-0" onclick="currentSlide(2, idx=0)">OBJ</span>
            <span class="vis dot slide-index-0" onclick="currentSlide(3, idx=0)">VIEW</span>
            <span class="sem dot slide-index-0" onclick="currentSlide(4, idx=0)">PROP</span>
            <span class="sem dot slide-index-0" onclick="currentSlide(5, idx=0)">LANG</span>
            <span class="sem dot slide-index-0" onclick="currentSlide(6, idx=0)">MO</span>
            <span class="sem dot slide-index-0" onclick="currentSlide(7, idx=0)">INT</span>
            <span class="vb dot slide-index-0" onclick="currentSlide(8, idx=0)">POSE</span>
            <span class="vb dot slide-index-0" onclick="currentSlide(9, idx=0)">ISC</span>
            <span class="vb dot slide-index-0" onclick="currentSlide(10, idx=0)">MOBJ</span>
            <span class="sb dot slide-index-0" onclick="currentSlide(11, idx=0)">SMO</span>
            <!-- <span class="sb dot slide-index-0" onclick="currentSlide(13, idx=0)">VRB</span> -->
            <span class="vsb dot slide-index-0" onclick="currentSlide(12, idx=0)">NOBJ</span>
        </div>

        <br>
        <hr class="section-divider">

        <!-- KNIFE -->
        <div class="full-slider-container">

            <!-- BASE -->
            <div class="video-container base-task" style="text-align: center; display:inline; float:left; width: 48%;">
                <video width="85%" controls loop autoplay muted>
                    <source src="videos/knife/knife_base.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p><b>BASE TASK</b>: Put knife on plate</p>
            </div>

            <div class="slideshow-container" style="width: 48%; display: inline-block; float: right;">


                <!-- DISTRACTORS -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/knife_distractors.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-SC</b>: <i>distractors</i></p>
                </div>

                <!-- VISUAL SCENE -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/knife_orange_plate.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-OBJ</b>: <i>orange plate</i></p>
                </div>

                <!--VISUAL VIEW -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/knife_camera.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-VIEW</b>: <i>new camera view</i></p>
                </div>

                <!-- SEMANTIC OBJECT PROP -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/knife/knife_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-PROP</b>: Put the gray and green object on the plate</p>
                </div>

                <!-- SEMANTIC LANG REPHRASE -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/knife/knife_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-LANG</b>: Lift knife and place on plate</p>
                </div>

                <!-- SEMANTIC MULTI OBJ REFERING -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/knife/knife_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-MO</b>: Put the object that is in the sink on the plate</p>
                </div>

                <!-- SEMANTIC INTERNET -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/knife/knife_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-INT</b>: Put the knif on the plate <i>(typo)</i></p>
                </div>

                <!-- VISUAL+BEHAVIORAL POSE -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/knife_right.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-POSE</b>: <i>knife to the right</i></p>
                </div>

                <!-- VISUAL+BEHAVIORAL SCENE ELEMENTS -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/knife_shorter_table.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-ISC</b>: <i>shorter table height</i></p>
                </div>


                <!-- VISUAL+BEHAVIORAL OBJECT MORPH -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/small_knife.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-MOBJ</b>: <i>smaller knife</i></p>
                </div>

                <!-- SEMANTIC+BEHAVIORAL NEW VERB  -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/rotate_knife.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>SB-VRB</b>: Rotate knife clockwise</p>
                </div>

                <!-- VISUAL+SEMANTIC+BEHAVIORAL NEW OBJECT -->
                <div class="video-container slide-index-1" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/knife/pizza.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VSB-NOBJ</b>: Put pizza on plate</p>
                </div>

                <div>
                    <!-- Next and previous buttons -->
                    <a class="prev" onclick="plusSlides(-1, idx=1)">&#10094;</a>
                    <a class="next" onclick="plusSlides(1, idx=1)">&#10095;</a>
                </div>
            </div>

        </div>

        <br>

        <div style="text-align: center; display: block;">
            <span class="vis dot slide-index-1" onclick="currentSlide(1, idx=1)">SC</span>
            <span class="vis dot slide-index-1" onclick="currentSlide(2, idx=1)">OBJ</span>
            <span class="vis dot slide-index-1" onclick="currentSlide(3, idx=1)">VIEW</span>
            <span class="sem dot slide-index-1" onclick="currentSlide(4, idx=1)">PROP</span>
            <span class="sem dot slide-index-1" onclick="currentSlide(5, idx=1)">LANG</span>
            <span class="sem dot slide-index-1" onclick="currentSlide(6, idx=1)">MO</span>
            <span class="sem dot slide-index-1" onclick="currentSlide(7, idx=1)">INT</span>
            <span class="vb dot slide-index-1" onclick="currentSlide(8, idx=1)">POSE</span>
            <span class="vb dot slide-index-1" onclick="currentSlide(9, idx=1)">ISC</span>
            <span class="vb dot slide-index-1" onclick="currentSlide(10, idx=1)">MOBJ</span>
            <!-- <span class="sb dot slide-index-1" onclick="currentSlide(11, idx=1)">SMO</span> -->
            <span class="sb dot slide-index-1" onclick="currentSlide(11, idx=1)">VRB</span>
            <span class="vsb dot slide-index-1" onclick="currentSlide(12, idx=1)">NOBJ</span>
        </div>

        <br>
        <hr class="section-divider">

        <!-- POT -->
        <div class="full-slider-container">

            <!-- BASE -->
            <div class="video-container base-task" style="text-align: center; display:inline; float:left; width: 48%;">
                <video width="85%" controls loop autoplay muted>
                    <source src="videos/pot/pot_base.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p><b>BASE TASK</b>: Flip pot upright which is in sink</p>
            </div>

            <div class="slideshow-container" style="width: 48%; display: inline-block; float: right;">


                <!-- DISTRACTORS -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/pot_distractors.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-SC</b>: <i>distractors</i></p>
                </div>

                <!-- VISUAL SCENE -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/pot_green_sink.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-SC</b>: <i>green sink</i></p>
                </div>

                <!--VISUAL VIEW -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/pot_camera.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-VIEW</b>: <i>new camera view</i></p>
                </div>

                <!-- SEMANTIC OBJECT PROP -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/pot/pot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-PROP</b>: Flip the gray object upright which is in sink</p>
                </div>

                <!-- SEMANTIC LANG REPHRASE -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/pot/pot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-LANG</b>: Lift pot upright and place in sink</p>
                </div>

                <!-- SEMANTIC MULTI OBJ REFERING -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/pot/pot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-MO</b>: Flip the object that is in the sink upright</p>
                </div>

                <!-- SEMANTIC INTERNET -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/pot/pot_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-INT</b>: Flip the object that can be used for boiling water upright</p>
                </div>

                <!-- VISUAL+BEHAVIORAL POSE -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/pot_angled.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-POSE</b>: <i>pot angled</i></p>
                </div>

                <!-- VISUAL+BEHAVIORAL SCENE ELEMENTS -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/pot_shorter_table.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-ISC</b>: <i>shorter table height</i></p>
                </div>


                <!-- VISUAL+BEHAVIORAL OBJECT MORPH -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/thin_pot.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-MOBJ</b>: <i>smaller pot</i></p>
                </div>

                <!-- SEMANTIC+BEHAVIORAL NEW VERB  -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/pot_to_left.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>SB-VRB</b>: Move pot to the left side of the sink</p>
                </div>

                <!-- VISUAL+SEMANTIC+BEHAVIORAL NEW OBJECT -->
                <div class="video-container slide-index-2" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/pot/cup.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VSB-NOBJ</b>: Flip cup upright which is in sink</p>
                </div>

                <div>
                    <!-- Next and previous buttons -->
                    <a class="prev" onclick="plusSlides(-1, idx=2)">&#10094;</a>
                    <a class="next" onclick="plusSlides(1, idx=2)">&#10095;</a>
                </div>
            </div>

        </div>

        <br>

        <div style="text-align: center; display: block;">
            <span class="vis dot slide-index-2" onclick="currentSlide(1, idx=2)">SC</span>
            <span class="vis dot slide-index-2" onclick="currentSlide(2, idx=2)">SC(2)</span>
            <span class="vis dot slide-index-2" onclick="currentSlide(3, idx=2)">VIEW</span>
            <span class="sem dot slide-index-2" onclick="currentSlide(4, idx=2)">PROP</span>
            <span class="sem dot slide-index-2" onclick="currentSlide(5, idx=2)">LANG</span>
            <span class="sem dot slide-index-2" onclick="currentSlide(6, idx=2)">MO</span>
            <span class="sem dot slide-index-2" onclick="currentSlide(7, idx=2)">INT</span>
            <span class="vb dot slide-index-2" onclick="currentSlide(8, idx=2)">POSE</span>
            <span class="vb dot slide-index-2" onclick="currentSlide(9, idx=2)">ISC</span>
            <span class="vb dot slide-index-2" onclick="currentSlide(10, idx=2)">MOBJ</span>
            <!-- <span class="sb dot slide-index-2" onclick="currentSlide(11, idx=2)">SMO</span> -->
            <span class="sb dot slide-index-2" onclick="currentSlide(11, idx=2)">VRB</span>
            <span class="vsb dot slide-index-2" onclick="currentSlide(12, idx=2)">NOBJ</span>
        </div>

        <br>
        <hr class="section-divider">

        <!-- plate -->
        <div class="full-slider-container">

            <!-- BASE -->
            <div class="video-container base-task" style="text-align: center; display:inline; float:left; width: 48%;">
                <video width="85%" controls loop autoplay muted>
                    <source src="videos/plate/plate_base.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p><b>BASE TASK</b>: Put plate in sink</p>
            </div>

            <div class="slideshow-container" style="width: 48%; display: inline-block; float: right;">


                <!-- DISTRACTORS -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/plate_distractors.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-SC</b>: <i>distractors</i></p>
                </div>

                <!-- VISUAL SCENE -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/gray_plate.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-OBJ</b>: <i>gray plate</i></p>
                </div>

                <!--VISUAL VIEW -->
                <!-- <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/plate_camera.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>V-VIEW</b>: <i>new camera view</i></p>
                </div> -->

                <!-- SEMANTIC OBJECT PROP -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/plate/plate_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-PROP</b>: Put the pink object in the sink</p>
                </div>

                <!-- SEMANTIC LANG REPHRASE -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/plate/plate_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-LANG</b>: Lift plate and place in sink</p>
                </div>

                <!-- SEMANTIC MULTI OBJ REFERING -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/plate/plate_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-MO</b>: Put the object that is in the drying rack in the sink</p>
                </div>

                <!-- SEMANTIC INTERNET -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted style="opacity: 0.6;">
                        <source src="videos/plate/plate_base.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>S-INT</b>: Put plait on plate <i>(typo)</i></p>
                </div>

                <!-- VISUAL+BEHAVIORAL POSE -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/plate_closer.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-POSE</b>: <i>plate closer</i></p>
                </div>

                <!-- VISUAL+BEHAVIORAL SCENE ELEMENTS -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/plate_shorter_table.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-ISC</b>: <i>shorter table height</i></p>
                </div>


                <!-- VISUAL+BEHAVIORAL OBJECT MORPH -->
                <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/red_bowl.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VB-MOBJ</b>: <i>red bowl-like plate</i></p>
                </div>

                <!-- SEMANTIC+BEHAVIORAL NEW VERB  -->
                <!-- <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/plate_to_counter.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>SB-SMO</b>: Put plate on counter</p>
                </div> -->

                <!-- VISUAL+SEMANTIC+BEHAVIORAL NEW OBJECT -->
                <!-- <div class="video-container slide-index-3" style="text-align: center;">
                    <video width="85%" controls loop autoplay muted>
                        <source src="videos/plate/spoon.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><b>VSB-NOBJ</b>: Put spoon in sink</p>
                </div> -->

                <div>
                    <!-- Next and previous buttons -->
                    <a class="prev" onclick="plusSlides(-1, idx=3)">&#10094;</a>
                    <a class="next" onclick="plusSlides(1, idx=3)">&#10095;</a>
                </div>
            </div>

        </div>

        <br>

        <div style="text-align: center; display: block;">
            <span class="vis dot slide-index-3" onclick="currentSlide(1, idx=3)">SC</span>
            <span class="vis dot slide-index-3" onclick="currentSlide(2, idx=3)">OBJ</span>
            <!-- <span class="vis dot slide-index-3" onclick="currentSlide(3, idx=3)">VIEW</span> -->
            <span class="sem dot slide-index-3" onclick="currentSlide(3, idx=3)">PROP</span>
            <span class="sem dot slide-index-3" onclick="currentSlide(4, idx=3)">LANG</span>
            <span class="sem dot slide-index-3" onclick="currentSlide(5, idx=3)">MO</span>
            <span class="sem dot slide-index-3" onclick="currentSlide(6, idx=3)">INT</span>
            <span class="vb dot slide-index-3" onclick="currentSlide(7, idx=3)">POSE</span>
            <span class="vb dot slide-index-3" onclick="currentSlide(8, idx=3)">ISC</span>
            <span class="vb dot slide-index-3" onclick="currentSlide(9, idx=3)">MOBJ</span>
            <!-- <span class="sb dot slide-index-3" onclick="currentSlide(11, idx=3)">SMO</span> -->
            <!-- <span class="vsb dot slide-index-3" onclick="currentSlide(12, idx=3)">NOBJ</span> -->
        </div>

        <br>
        <hr class="section-divider">

        <h2>Generate Your Own ★-Gen Conditions</h2>
        <br>

        <p>
            Here we provide a demo of using Gemini 2.0 Flash to automatically generate evaluation conditions for a base task according to ★-Gen.
            First, provide a Gemini API key, which can be generated <a href="https://aistudio.google.com/u/1/apikey">here</a> (this will only be stored locally).
            Then, provide a base task by uploading a scene image (under 1 MB) and providing a language instruction.
            You may then choose an axis from ★-Gen from one of the options in the drop-down menu, and Gemini will suggest new perturbed tasks (as text) for evaluating the chosen axis.
            <br>
            <b>Disclaimer</b>: The generated perturbations are not guaranteed to accurately reflect the chosen axis.
        </p>

        <div id="react-widget"></div>
        <!-- Include React JavaScript from react-widget folder -->
        <script src="react-widget/assets/index-C4s6VJKU.js"></script>

        <br>
        <hr class="section-divider">

         <div class="row">
            <div class="col-md-12">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@inproceedings{taxonomy2025arxiv,
    title=A Taxonomy for Evaluating Generalist Robot Policies,
    author={Jensen Gao and Suneel Belkhale and Sudeep Dasari and Ashwin Balakrishna and Dhruv Shah and Dorsa Sadigh},
    booktitle={https://arxiv.org},
    year={2025}
}</textarea>
                </div>
                </div>
            </div>

        </div>


        <div class="row">
            <div class="col-md-12">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="http://jonbarron.info/">Jon Barron</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
